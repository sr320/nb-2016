{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example _de novo_ RADseq assembly using _pyRAD_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modification to start looking at Ostrea data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------  \n",
    "\n",
    "Please direct questions about _pyRAD_ analyses to the google group thread ([link](https://groups.google.com/forum/#!forum/pyrad-users))  \n",
    "\n",
    "--------------  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+  This tutorial is meant as a walkthrough for a single-end RADseq analyses. If you have not yet read the [__full tutorial__](http://www.dereneaton.com/software/pyrad), you should start there for a broader description of how _pyRAD_ works. If you are new to RADseq analyses, this tutorial will provide a simple overview of how to execute _pyRAD_, what the data files look like, and how to check that your analysis is working, and the expected output formats.  \n",
    "\n",
    "\n",
    "\n",
    "+  Each cell in this tutorial begins with the header (%%bash) indicating that the code should be executed in a command line shell, for example by copying and pasting the text into your terminal (but excluding the %%bash header).\n",
    "\n",
    "-------------  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by executing the command below. This will download an example simulated RADseq data set and unarchive it into your current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/Users/sr320/git-repos/nb-2016/util'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/web-1/halfshell/working-directory\n"
     ]
    }
   ],
   "source": [
    "cd /Volumes/web-1/halfshell/working-directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/web-1/halfshell/working-directory/16-04-15b\n"
     ]
    }
   ],
   "source": [
    "cd 16-04-15b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1HL_1A_1.fq.gz*\r\n",
      "1HL_1A_2.fq.gz*\r\n",
      "1HL_2A_1.fq.gz*\r\n",
      "1HL_2A_2.fq.gz*\r\n",
      "1HL_3A_1.fq.gz*\r\n",
      "1HL_3A_2.fq.gz*\r\n",
      "1HL_4A_1.fq.gz*\r\n",
      "1HL_4A_2.fq.gz*\r\n",
      "1NF_1A_1.fq.gz*\r\n",
      "1NF_1A_2.fq.gz*\r\n"
     ]
    }
   ],
   "source": [
    "ls | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We begin by creating the params.txt file which is used to set all parameters for an analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------   \n",
    "\n",
    "The params file lists on each line one parameter followed by a __##__ mark, after which any comments can be left. In the comments section there is a description of the parameter and in parentheses the step of the analysis affected by the parameter. Lines 1-12 are required, the remaining lines are optional. The params.txt file is further described in the general tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look at the default settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==** parameter inputs for pyRAD version 3.0.64  **======================== affected step ==\n",
      "./                        ## 1. Working directory                                 (all)\n",
      "./*.fastq.gz              ## 2. Loc. of non-demultiplexed files (if not line 18)  (s1)\n",
      "./*.barcodes              ## 3. Loc. of barcode file (if not line 18)             (s1)\n",
      "/Applications/bioinfo/vsearch-1.11.1-osx-x86_64/bin/vsearch                   ## 4. command (or path) to call vsearch (or usearch)    (s3,s6)\n",
      "/Applications/bioinfo/muscle3.8.31_i86darwin64                    ## 5. command (or path) to call muscle                  (s3,s7)\n",
      "CWGC                     ## 6. Restriction overhang (e.g., C|TGCAG -> TGCAG)     (s1,s2)\n",
      "6                         ## 7. N processors (parallel)                           (all)\n",
      "5                         ## 8. Mindepth: min coverage for a cluster              (s4,s5)\n",
      "4                         ## 9. NQual: max # sites with qual < 20 (or see line 20)(s2)\n",
      ".88                       ## 10. Wclust: clustering threshold as a decimal        (s3,s6)\n",
      "gbs                       ## 11. Datatype: rad,gbs,pairgbs,pairddrad,(others:see docs)(all)\n",
      "50                         ## 12. MinCov: min samples in a final locus             (s7)\n",
      "20                         ## 13. MaxSH: max inds with shared hetero site          (s7)\n",
      "c88d6m4p3                 ## 14. Prefix name for final output (no spaces)         (s7)\n",
      "==== optional params below this line ===================================  affected step ==\n",
      "                       ## 15.opt.: select subset (prefix* only selector)            (s2-s7)\n",
      "                       ## 16.opt.: add-on (outgroup) taxa (list or prefix*)         (s6,s7)\n",
      "                       ## 17.opt.: exclude taxa (list or prefix*)                   (s7)\n",
      "                       ## 18.opt.: loc. of de-multiplexed data                      (s2)\n",
      "                       ## 19.opt.: maxM: N mismatches in barcodes (def= 1)          (s1)\n",
      "                       ## 20.opt.: phred Qscore offset (def= 33)                    (s2)\n",
      "                       ## 21.opt.: filter: def=0=NQual 1=NQual+adapters. 2=strict   (s2)\n",
      "                       ## 22.opt.: a priori E,H (def= 0.001,0.01, if not estimated) (s5)\n",
      "                       ## 23.opt.: maxN: max Ns in a cons seq (def=5)               (s5)\n",
      "                       ## 24.opt.: maxH: max heterozyg. sites in cons seq (def=5)   (s5)\n",
      "                       ## 25.opt.: ploidy: max alleles in cons seq (def=2;see docs) (s4,s5)\n",
      "                       ## 26.opt.: maxSNPs: (def=100). Paired (def=100,100)         (s7)\n",
      "                       ## 27.opt.: maxIndels: within-clust,across-clust (def. 3,99) (s3,s7)\n",
      "                       ## 28.opt.: random number seed (def. 112233)              (s3,s6,s7)\n",
      "                       ## 29.opt.: trim overhang left,right on final loci, def(0,0) (s7)\n",
      "                       ## 30.opt.: output formats: p,n,a,s,v,u,t,m,k,g,* (see docs) (s7)\n",
      "                       ## 31.opt.: maj. base call at depth>x<mindepth (def.x=mindepth) (s5)\n",
      "                       ## 32.opt.: keep trimmed reads (def=0). Enter min length.    (s2)\n",
      "                       ## 33.opt.: max stack size (int), def= max(500,mean+2*SD)    (s3)\n",
      "                       ## 34.opt.: minDerep: exclude dereps with <= N copies, def=1 (s3)\n",
      "                       ## 35.opt.: use hierarchical clustering (def.=0, 1=yes)      (s6)\n",
      "                       ## 36.opt.: repeat masking (def.=1='dust' method, 0=no)      (s3,s6)\n",
      "                       ## 37.opt.: vsearch max threads per job (def.=6; see docs)   (s3,s6)\n",
      "==== optional: list group/clade assignments below this line (see docs) ==================\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat params.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To change parameters you can edit params.txt in any text editor. Here to automate things I use the script below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's have a look at the changes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------   \n",
    "\n",
    "__Let's take a look at what the raw data look like.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your input data will be in fastQ format, usually ending in .fq or .fastq. Your data could be split among multiple files, or all within a single file (de-multiplexing goes much faster if they happen to be split into multiple files). The file/s may be compressed with gzip so that they have a .gz ending, but they do not need to be. The location of these files should be entered on line 2 of the params file. Below are the first three reads in the example file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m1HL_1A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1HL_3A_2.fq.gz\u001b[m\u001b[m* \u001b[31m1NF_2A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1NF_5A_2.fq.gz\u001b[m\u001b[m* \u001b[31m1SN_3A_1.fq.gz\u001b[m\u001b[m*\r\n",
      "\u001b[31m1HL_1A_2.fq.gz\u001b[m\u001b[m* \u001b[31m1HL_4A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1NF_2A_2.fq.gz\u001b[m\u001b[m* \u001b[31m1SN_1A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1SN_3A_2.fq.gz\u001b[m\u001b[m*\r\n",
      "\u001b[31m1HL_2A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1HL_4A_2.fq.gz\u001b[m\u001b[m* \u001b[31m1NF_4A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1SN_1A_2.fq.gz\u001b[m\u001b[m* \u001b[31m1SN_4A_1.fq.gz\u001b[m\u001b[m*\r\n",
      "\u001b[31m1HL_2A_2.fq.gz\u001b[m\u001b[m* \u001b[31m1NF_1A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1NF_4A_2.fq.gz\u001b[m\u001b[m* \u001b[31m1SN_2A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1SN_4A_2.fq.gz\u001b[m\u001b[m*\r\n",
      "\u001b[31m1HL_3A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1NF_1A_2.fq.gz\u001b[m\u001b[m* \u001b[31m1NF_5A_1.fq.gz\u001b[m\u001b[m* \u001b[31m1SN_2A_2.fq.gz\u001b[m\u001b[m* \u001b[31mparams.txt\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "!gunzip *.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1HL_10A_1.fq*\r\n",
      "1HL_10A_2.fq*\r\n",
      "1HL_10A_2.fq.gz*\r\n",
      "1HL_11A_1.fq.gz*\r\n",
      "1HL_11A_2.fq.gz*\r\n",
      "1HL_12A_1.fq.gz*\r\n",
      "1HL_12A_2.fq.gz*\r\n",
      "1HL_13A_1.fq.gz*\r\n",
      "1HL_13A_2.fq.gz*\r\n",
      "1HL_14A_1.fq.gz*\r\n"
     ]
    }
   ],
   "source": [
    "ls | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@lane1_fakedata0_R1_0 1:N:0:\n",
      "TTTTAATGCAGTGAGTGGCCATGCAATATATATTTACGGGCGCATAGAGACCCTCAAGACTGCCAACCGGGTGAATCACTATTTGCTTAG\n",
      "+\n",
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\n",
      "@lane1_fakedata0_R1_1 1:N:0:\n",
      "TTTTAATGCAGTGAGTGGCCATGCAATATATATTTACGGGCGCATAGAGACCCTCAAGACTGCCAACCGGGTGAATCACTATTTGCTTAG\n",
      "+\n",
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\n",
      "@lane1_fakedata0_R1_2 1:N:0:\n",
      "TTTTAATGCAGTGAGTGGCCATGCAATATATATTTACGGGCGCATAGAGACCCTCAAGACTGCCAACCGGGTGAATCACTATTTGCTTAG\n",
      "+\n",
      "BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "less simRADs_R1.fastq | head -n 12 | cut -c 1-90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------   \n",
    "\n",
    "Each read takes four lines. The first is the name of the read (its location on the plate). The second line contains the sequence data. The third line is a spacer. And the fourth line the quality scores for the base calls. In this case arbitrarily high since the data were simulated. \n",
    "\n",
    "These are 100 bp single-end reads prepared as RADseq. The first six bases form the barcode and the next five bases (TGCAG) the restriction site overhang. All following bases make up the sequence data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------   \n",
    "\n",
    "## Step 1: de-multiplexing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "already done by bgi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: quality filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "     ------------------------------------------------------------\n",
      "      pyRAD : RADseq for phylogenetics & introgression analyses\n",
      "     ------------------------------------------------------------\n",
      "\n",
      "\tstep 2: editing raw reads \n",
      "\t........................"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pyRAD -p params.txt -s 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1HL_1A_1.edit\n",
      "1HL_1A_2.edit\n",
      "1HL_2A_1.edit\n",
      "1HL_2A_2.edit\n",
      "1HL_3A_1.edit\n",
      "1HL_3A_2.edit\n",
      "1HL_4A_1.edit\n",
      "1HL_4A_2.edit\n",
      "1NF_1A_1.edit\n",
      "1NF_1A_2.edit\n",
      "1NF_2A_1.edit\n",
      "1NF_2A_2.edit\n",
      "1NF_4A_1.edit\n",
      "1NF_4A_2.edit\n",
      "1NF_5A_1.edit\n",
      "1NF_5A_2.edit\n",
      "1SN_1A_1.edit\n",
      "1SN_1A_2.edit\n",
      "1SN_2A_1.edit\n",
      "1SN_2A_2.edit\n",
      "1SN_3A_1.edit\n",
      "1SN_3A_2.edit\n",
      "1SN_4A_1.edit\n",
      "1SN_4A_2.edit\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls edits/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filtered data are written in fasta format (quality scores removed) into a new directory called edits/. Below I show a preview of the file which you can view most easily using the `less` command (I use `head` here to make it fit in the text window better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1HL_1A_1_0_r1\n",
      "CTGCAGTTATGGGTTTAGTAATTAGATTAGTTGTGGCTTGCTTAGAATATAATATTCTATTTCAAGCGCAACATATTGCA\n",
      ">1HL_1A_1_1_r1\n",
      "CTGCTTCACATGAGGAAAAAGTTCCAAAAGAAGACAACAGAAAAATGCCAATGAAGAGAATAAGAAATATCAATCAAAAA\n",
      ">1HL_1A_1_2_r1\n",
      "CTGCGGTGCCTGAGAAATAAAAAAAAGTTTGTTCTGCCTAAAGCTGAGATTGGTACAGTGGAACAAAGTGCTGAAGAAAG\n",
      ">1HL_1A_1_3_r1\n",
      "CTGCATTAAATCGGCATATTTTTATTTTTTATAGGATTGAATATATAAATTTTCAGAAATGAATACAAAAACCGAATAGC\n",
      ">1HL_1A_1_4_r1\n",
      "CTGCACATCAAGAAAGGGGCAGGGCCAACATCGGTAAGGAAGGGCAAGGTTCAGAAATAGGCAGGGCAAACAGTATGTCG\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -n 10 edits/1HL_1A_1.edit | cut -c 1-80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: clustering within-samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 de-replicates and then clusters reads within each sample by the set clustering threshold and writes the clusters to new files in a directory called clust.xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "     ------------------------------------------------------------\n",
      "      pyRAD : RADseq for phylogenetics & introgression analyses\n",
      "     ------------------------------------------------------------\n",
      "\n",
      "\n",
      "\tde-replicating files for clustering...\n",
      "\n",
      "\tstep 3: within-sample clustering of 24 samples at \n",
      "\t        '.88' similarity. Running 6 parallel jobs\n",
      "\t \twith up to 6 threads per job. If needed, \n",
      "\t\tadjust to avoid CPU and MEM limits\n",
      "\n",
      "\tsample 1NF_2A_1 finished, 211397 loci\n",
      "\tsample 1SN_4A_1 finished, 223325 loci\n",
      "\tsample 1NF_4A_1 finished, 227834 loci\n",
      "\tsample 1SN_4A_2 finished, 262292 loci\n",
      "\tsample 1NF_2A_2 finished, 254170 loci\n",
      "\tsample 1NF_4A_2 finished, 273403 loci\n",
      "\tsample 1SN_2A_1 finished, 211909 loci\n",
      "\tsample 1SN_1A_2 finished, 233509 loci\n",
      "\tsample 1SN_1A_1 finished, 196225 loci\n",
      "\tsample 1SN_2A_2 finished, 250692 loci\n",
      "\tsample 1NF_5A_1 finished, 201878 loci\n",
      "\tsample 1HL_2A_2 finished, 220793 loci\n",
      "\tsample 1NF_5A_2 finished, 235210 loci\n",
      "\tsample 1HL_2A_1 finished, 188223 loci\n",
      "\tsample 1HL_4A_1 finished, 187837 loci\n",
      "\tsample 1HL_4A_2 finished, 217303 loci\n",
      "\tsample 1SN_3A_1 finished, 235474 loci\n",
      "\tsample 1SN_3A_2 finished, 266870 loci\n",
      "\tsample 1HL_1A_2 finished, 207572 loci\n",
      "\tsample 1NF_1A_1 finished, 127769 loci\n",
      "\tsample 1HL_3A_2 finished, 241082 loci\n",
      "\tsample 1HL_1A_1 finished, 180183 loci\n",
      "\tsample 1HL_3A_1 finished, 214916 loci\n",
      "\tsample 1NF_1A_2 finished, 145020 loci\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pyRAD -p params.txt -s 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, I recommend you use the unix command 'less' to look at the clustS files. These contain each cluster separated by \"//\". For the first few clusters below you can see that there is one or two alleles in the cluster and one or a few reads that contained a (simulated) sequencing error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"clust.85/1A0.clustS.gz\" may be a binary file.  See it anyway? "
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "less clust.85/1A0.clustS.gz | head -n 26 | cut -c 1-80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "\n",
    "The stats output tells you how many clusters were found, and their mean depth of coverage. It also tells you how many pass  your minimum depth setting. You can use this information to decide if you wish to increase or decrease the mindepth before it is applied for making consensus base calls in steps 4 & 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "taxa\ttotal\tdpt.me\tdpt.sd\td>4.tot\td>4.me\td>4.sd\tbadpairs\n",
      "1HL_1A_1\t180183\t9.1\t57.224\t65738\t21.779\t93.383\t0\n",
      "1HL_1A_2\t207572\t7.509\t38.931\t64027\t20.606\t68.289\t0\n",
      "1HL_2A_1\t188223\t10.441\t62.134\t72867\t24.079\t98.323\t0\n",
      "1HL_2A_2\t220793\t8.49\t41.232\t71187\t22.868\t70.469\t0\n",
      "1HL_3A_1\t214916\t7.441\t38.217\t66187\t20.338\t67.083\t0\n",
      "1HL_3A_2\t241082\t6.418\t31.632\t64417\t19.647\t59.191\t0\n",
      "1HL_4A_1\t187837\t9.827\t52.59\t71766\t22.797\t83.456\t0\n",
      "1HL_4A_2\t217303\t8.232\t45.561\t69785\t22.148\t78.592\t0\n",
      "1NF_1A_1\t127769\t7.742\t35.842\t45123\t18.547\t58.781\t0\n",
      "1NF_1A_2\t145020\t6.633\t29.957\t43746\t18.055\t52.782\t0\n",
      "1NF_2A_1\t211397\t11.667\t65.516\t85433\t26.21\t101.314\t0\n",
      "1NF_2A_2\t254170\t9.375\t51.79\t83372\t25.271\t88.313\t0\n",
      "1NF_4A_1\t227834\t11.261\t66.186\t91019\t25.482\t103.087\t0\n",
      "1NF_4A_2\t273403\t9.101\t54.68\t88937\t24.634\t93.979\t0\n",
      "1NF_5A_1\t201878\t9.78\t48.097\t77386\t22.607\t75.937\t0\n",
      "1NF_5A_2\t235210\t8.207\t41.016\t75595\t22.064\t70.352\t0\n",
      "1SN_1A_1\t196225\t11.115\t62.818\t77527\t25.362\t98.238\t0\n",
      "1SN_1A_2\t233509\t9.044\t51.384\t75550\t24.548\t88.337\t0\n",
      "1SN_2A_1\t211909\t10.364\t62.516\t79250\t24.699\t100.6\t0\n",
      "1SN_2A_2\t250692\t8.451\t49.85\t77415\t23.717\t87.795\t0\n",
      "1SN_3A_1\t235474\t7.488\t40.336\t70207\t21.057\t72.058\t0\n",
      "1SN_3A_2\t266870\t6.457\t34.663\t68439\t20.509\t66.462\t0\n",
      "1SN_4A_1\t223325\t10.48\t54.88\t85795\t24.404\t86.738\t0\n",
      "1SN_4A_2\t262292\t8.558\t42.398\t83629\t23.37\t72.896\t0\n",
      "\n",
      "    ## total = total number of clusters, including singletons\n",
      "    ## dpt.me = mean depth of clusters\n",
      "    ## dpt.sd = standard deviation of cluster depth\n",
      "    ## >N.tot = number of clusters with depth greater than N\n",
      "    ## >N.me = mean depth of clusters with depth greater than N\n",
      "    ## >N.sd = standard deviation of cluster depth for clusters with depth greater than N\n",
      "    ## badpairs = mismatched 1st & 2nd reads (only for paired ddRAD data)\n",
      "\n",
      "HISTOGRAMS\n",
      "\n",
      "    \n",
      "sample: 1HL_1A_1\n",
      "bins\tdepth_histogram\tcnts\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -n 40 stats/s3.clusters.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps 4 & 5: Call consensus sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 jointly infers the error-rate and heterozygosity across samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pyRAD -p params.txt -s 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxa\tH\tE\n",
      "3K0\t0.00135982\t0.00048078\t\n",
      "1C0\t0.00134858\t0.00048372\t\n",
      "1D0\t0.00135375\t0.00048822\t\n",
      "3I0\t0.00129751\t0.00048694\t\n",
      "2H0\t0.00133223\t0.00049211\t\n",
      "2F0\t0.00135365\t0.0004995\t\n",
      "2E0\t0.00126915\t0.00051556\t\n",
      "1B0\t0.00149924\t0.00049663\t\n",
      "1A0\t0.00136043\t0.00051028\t\n",
      "3J0\t0.00144422\t0.0005089\t\n",
      "2G0\t0.00138185\t0.00051206\t\n",
      "3L0\t0.00143349\t0.00051991\t\n",
      "3K0\t0.00135982\t0.00048078\t\n",
      "1C0\t0.00134858\t0.00048372\t\n",
      "1D0\t0.00135375\t0.00048822\t\n",
      "3I0\t0.00129751\t0.00048694\t\n",
      "2H0\t0.00133223\t0.00049211\t\n",
      "2F0\t0.00135365\t0.0004995\t\n",
      "2E0\t0.00126915\t0.00051556\t\n",
      "1B0\t0.00149924\t0.00049663\t\n",
      "1A0\t0.00136043\t0.00051028\t\n",
      "3J0\t0.00144422\t0.0005089\t\n",
      "2G0\t0.00138185\t0.00051206\t\n",
      "3L0\t0.00143349\t0.00051991\t\n",
      "3K0\t0.00135982\t0.00048078\t\n",
      "1C0\t0.00134858\t0.00048372\t\n",
      "1D0\t0.00135375\t0.00048822\t\n",
      "3I0\t0.00129751\t0.00048694\t\n",
      "2H0\t0.00133223\t0.00049211\t\n",
      "2F0\t0.00135365\t0.0004995\t\n",
      "2E0\t0.00126915\t0.00051556\t\n",
      "1B0\t0.00149924\t0.00049663\t\n",
      "1A0\t0.00136043\t0.00051028\t\n",
      "3J0\t0.00144422\t0.0005089\t\n",
      "2G0\t0.00138185\t0.00051206\t\n",
      "3L0\t0.00143349\t0.00051991\t\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "less stats/Pi_E_estimate.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 calls consensus sequences using the parameters inferred above, and filters for paralogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pyRAD -p params.txt -s 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The stats output for step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "less stats/s5.consens.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Cluster across samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6 clusters consensus sequences across samples. It will print its progress to the screen. This uses 6 threads by default. If you enter 0 for param 37 it will use all available processors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pyRAD -p params.txt -s 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Assemble final data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is to output data only for the loci that you want to have included in your data set. This filters once again for potential paralogs or highly repetitive regions, and includes options to minimize the amount of missing data in the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pyRAD -p params.txt -s 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final stats output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "less stats/c85m4p3.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------  \n",
    "\n",
    "## Output formats ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created 11 output files from our analysis. The standard two (.loci and .excluded_loci), as well as the 9 additional ones listed in the params file. These are all shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "ls outfiles/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loci format  \n",
    "The \".loci\" file contains each locus listed in a fasta-like format that also shows which sites are variable below each locus. Autapomorphies are listed as '-' and shared SNPs as '*'. This is a custom format that is human readable and also used as input to perform D-statistic tests in pyRAD. This is the easiest way to visualize your results. I recommend viewing the file with the command `less`. Below I use a head and cut to make it easy to view in this window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -n 39 outfiles/c85m4p3.loci | cut -c 1-75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHY format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -n 50 outfiles/c85m4p3.phy | cut -c 1-85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -n 50 outfiles/c85m4p3.nex | cut -c 1-85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alleles format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -n 50 outfiles/c85m4p3.alleles| cut -c 1-85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STRUCTURE (.str) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -n 50 outfiles/c85m4p3.str | cut -c 1-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENO (.geno) format (used in _Admixture_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -n 40 outfiles/c85m4p3.geno "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNPs format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -n 50 outfiles/c85m4p3.snps | cut -c 1-85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNLINKED_SNPs format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -n 50 outfiles/c85m4p3.unlinked_snps | cut -c 1-85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTHER FORMATS  \n",
    "\n",
    "You may also produce some more complicated formatting options that involve pooling individuals into groups or populations. This can be done for the \"treemix\" and \"migrate\" outputs, which are formatted for input into the programs _TreeMix_ and _migrate-n_, respectively. Grouping individuals into populations is done with the final lines of the params file as shown below, and similar to the assignment of individuals into clades for hierarchical clustering (see full tutorial). \n",
    "\n",
    "Each line designates a group, and has three arguments that are separated by space or tab. The first is the group name, the second is the minimum number of individuals that must have data in that group for a locus to be included in the output, and the third is a list of the members of that group. Lists of taxa can include comma-separated names and wildcard selectors, like below. Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "## append group designations to the params file\n",
    "echo \"pop1 4 1A0,1B0,1C0,1D0 \" >> params.txt\n",
    "echo \"pop2 4 2E0,2F0,2G0,2H0 \" >> params.txt\n",
    "echo \"pop3 4 3* \" >> params.txt\n",
    "\n",
    "## view params file\n",
    "cat params.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating population output files  \n",
    "Now if we run _pyRAD_ with the 'm' (migrate) or 't' (treemix) output options, it will create their output files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "pyRAD -p params.txt -s 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREEMIX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "less outfiles/c85m4p3.treemix.gz | head -n 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIGRATE-n FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -n 40 outfiles/c85m4p3.migrate | cut -c 1-85"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
